# 是否开启apollo集中配置
# metaspace.apollo=false
# apollo对应id
# app.id=metaspace
# apollo对应地址
# apollo.meta=http://10.200.64.109:8080
# apollo对应集群
# apollo.cluster=default
# apollo对应metaspace
# apollo.bootstrap.namespaces = application
# apollo对应cacheDir地址
# apollo.cacheDir = F:/myself/metaspace/deploy/tmp
# apollo密钥
##apollo.accesskey.secret=fc8bdb7bf7e544128d43a08d47086377

#cluster name
#atlas.cluster.name=ms

#kerberos
#atlas.authentication.method.kerberos=true
atlas.authentication.principal=metaspace@PANEL.COM
atlas.authentication.keytab=/etc/bigdata/keytables/metaspace.keytab
metaspace.hive.principal=hive/panel-sp-2@PANEL.COM
metaspace.impala.principal=impala/panel-sp-2@PANEL.COM
#metaspace.impala.resource.pool=metaspace
#metaspace.hive.queue=metaspace

#hive
metaspace.hive.url=10.200.64.125:10000,10.200.64.130:10000
metaspace.hive.conf=/etc/hive/conf
metaspace.hdfs.conf=/etc/hdfs/conf
metaspace.hive.bin=/usr/bin

#hbase
metaspace.hbase.conf=/etc/hbase/conf
metaspace.impala.url=jdbc:impala://10.200.64.130:21050
metaspace.impala.kerberos.jdbc=AuthMech=1;KrbRealm=PANEL.COM;KrbHostFQDN=10.200.64.130;KrbServiceName=impala

#kakfa
atlas.kafka.hook.group.id=metaspace
atlas.kafka.mechanism=GSSAPI
atlas.kafka.sasl.kerberos.service.name=kafka
atlas.kafka.security.protocol=SASL_PLAINTEXT
atlas.kafka.zookeeper.connect=10.200.64.130:2181,10.200.64.125:2181,10.200.64.95:2181
atlas.kafka.bootstrap.servers=10.200.64.130:6667,10.200.64.125:6667,10.200.64.95:6667
#atlas.kafka.zookeeper.session.timeout.ms=10000
#atlas.kafka.zookeeper.connection.timeout.ms=10000
#atlas.kafka.zookeeper.sync.time.ms=2000
#atlas.kafka.enable.auto.commit=false
#atlas.kafka.session.timeout.ms=30000
#offset config, latest or earliest
#atlas.kafka.auto.offset.reset=earliest

#kafka kerberos
atlas.jaas.KafkaClient.loginModuleName = com.sun.security.auth.module.Krb5LoginModule
atlas.jaas.KafkaClient.loginModuleControlFlag = required
atlas.jaas.KafkaClient.option.useKeyTab = true
atlas.jaas.KafkaClient.option.storeKey = true
atlas.jaas.KafkaClient.option.serviceName = kafka
atlas.jaas.KafkaClient.option.keyTab=/etc/bigdata/keytables/metaspace.keytab
atlas.jaas.KafkaClient.option.principal=metaspace@PANEL.COM

#lineage
atlas.lineage.schema.query.hive_table=hive_table where __guid='%s'\, columns
atlas.lineage.schema.query.Table=Table where __guid='%s'\, columns

#solr
atlas.graph.index.search.solr.kerberos-enabled=false
atlas.graph.index.search.backend=solr
atlas.graph.index.search.solr.mode=cloud
atlas.graph.index.search.solr.zookeeper-url=10.200.64.131:2181,10.200.64.143:2181,10.200.64.127:2181
atlas.graph.index.search.solr.zookeeper-connect-timeout=60000
atlas.graph.index.search.solr.zookeeper-session-timeout=60000
atlas.graph.index.search.solr.wait-searcher=true

#graph
atlas.graph.storage.backend=hbase
atlas.graph.storage.hbase.table=metaspace_titan
atlas.graph.storage.hostname=10.200.64.130:2181,10.200.64.125:2181,10.200.64.95:2181

#notification
#atlas.notification.embedded=false
#atlas.notification.create.topics=true
#atlas.notification.replicas=1
#atlas.notification.topics=METASPACE_HOOK,METASPACE_ENTITIES

#sso
sso.login.url=http://10.200.60.36:8800
sso.info.url=http://10.200.60.36:8800/api/v2/info
sso.organization.url=https://10.200.60.36:8800/portal/api/v5/organization
sso.organization.count.url=http://10.200.60.36:8800/portal/api/v5/organizationsCount
sso.user.info.url=http://10.200.60.36:8800/portal/api/v5/getAccountByID
sso.organization.first.pid=00161824
# sso是否开启加密处理
#sso.encryption = false
# 加密公钥
#sso.encryption.public.key = c207aebc5d8fd4ebb00f7603f85cd7c2de2e80a14172c52270f47c52bf4f1ba7
# 加密私钥
#sso.encryption.private.key = 8dced042f7af2361842fb934dc6f87b2f370e263834c5222b76c5ec0764689c2

#secureplus
#metaspace.secureplus.enable=true
security.center.host=http://10.200.64.97:6080

#server
#atlas.server.http.port=21001
#atlas.server.https.port=21443
#atlas.server.bind.address=127.0.0.1
#如果开启ha，则需要填写所有主机访问地址，用逗号隔开
atlas.rest.address=http://127.0.0.1:21001

#是否启用HA
#atlas.server.ha.enabled=false
#atlas.server.ids=id1,id2
#atlas.server.address.id1={metaspace_host1}:21001
#atlas.server.address.id2={metaspace_host2}:21001
atlas.server.ha.zookeeper.connect=10.200.64.130:2181,10.200.64.125:2181,10.200.64.95:2181
#atlas.server.ha.zookeeper.session.timeout.ms=20000

#audit
atlas.audit.hbase.zookeeper.quorum=10.200.64.130:2181,10.200.64.125:2181,10.200.64.95:2181
#atlas.audit.hbase.tablename=METASPACE_ENTITY_AUDIT_EVENTS
#atlas.audit.zookeeper.session.timeout.ms=60000
#atlas.authorizer.impl=simple

#cache
#metaspace.cache.type=redis
#metaspace.cache.redis.host=10.200.64.130
#metaspace.cache.redis.port=6379
#metaspace.cache.redis.expiration=300
#metaspace.cache.redis.client.max=128
#metaspace.cache.redis.password=


#hystrix
#hystrix.threadpool.default.coreSize=10
#hystrix.threadpool.default.maxQueueSize=-1
#hystrix.command.default.execution.timeout.enabled=true
#hystrix.command.default.execution.isolation.thread.timeoutInMilliseconds=10000
#hystrix.command.default.circuitBreaker.sleepWindowInMilliseconds=5000
#hystrix.threadpool.default.maximumSize=10

#数据库配置
#metaspace.database.driverClassName=org.postgresql.Driver
metaspace.database.url=jdbc:postgresql://10.200.64.116:5432/metaspace?useUnicode=true&characterEncoding=UTF8
metaspace.database.username=metaspace
metaspace.database.password=metaspace
#metaspace.database.minPoolSize=5
#metaspace.database.maxPoolSize=20
#metaspace.database.maxIdleTime=60
#metaspace.database.checkoutTimeout=20000

#邮箱配置
#metaspace.mail.enable=false
#metaspace.mail.user=
#metaspace.mail.password=
#metaspace.mail.service.mail.transport.protocol=smtp
#metaspace.mail.service.mail.host=smtp.gridsum.com
#metaspace.mail.service.mail.smtp.port=25

#过滤datasocket的临时表，默认为 null
#atlas.hook.hive.hive_table.ignore.pattern=.*\\.datasocket_.*_\\w{4}_\\w*_\\d{13}@.*

#metaspace
metaspace.mobius.url=http://10.203.40.149:31193/v3/bigdata/gateway
#数据质量规则执行引擎 hive or impala
#metaspace.quality.engine=impala
metaspace.request.address=http://127.0.0.1:21001
#是否启用quartz
#metaspace.quartz.task.enable=true
# 临时文件存储
# metaspace.tmp.filepath=F:/tmp/metaspace
# okhttp读取超时时间
# metaspace.okhttp.read.timeout=30
metaspace.dataservice=true

# livy 地址
livy.uri=http://10.200.64.97:8998/batches
# livy 是否开启 kerberos
livy.need.kerberos=false
livy.server.auth.kerberos.principal=
livy.server.auth.kerberos.keytab=
# livy 提交后获取 appId 重试次数
livy.task.appId.retry.count=3

# hadoop fs 连接地址
fs.defaultFS=hdfs://panel-1:8020

metaspace.adapter.dir=/home/metaspace/metaspace/adapter

#kafka connector配置
#kafka.connect请求路径
oracle.kafka.connect.urls=http://192.168.8.129:8083
#oracle元数据topic
#oracle.metadata.topic=ORACLE_METADATA

#元数据采集任务执行完成后是否检查创建并开启kafka connector(开启kafka connector后可实时更新元数据)
#auto.add.kafka.connector = true

# 配置日志审计、操作模块的目录 true标识屏蔽掉指标设计、修饰词、时间限定、审批人管理、指标域授权
metaspace.operationlog.module.moon = true
# 创建数据源配置数据源类型，多个配置项用,隔开（目前支持MYSQL,POSTGRESQL,ORACLE,DB2,SQLSERVER）
metaspace.datasource.type = MYSQL,POSTGRESQL,ORACLE,DB2,SQLSERVER
# API项目管理-创建API配置数据源类型，多个配置项用,隔开（目前支持HIVE,IMPALA,MYSQL,POSTGRESQL,ORACLE,DB2,SQLSERVER）
metaspace.datasource.api.type = HIVE,IMPALA,MYSQL,POSTGRESQL,ORACLE,DB2,SQLSERVER
# 用户组管理-配置权限下页签列表，配置具体的编号（1:成员,2:技术目录权限,3:业务目录权限,4:数据源权限,5:项目权限,6:指标域权限），metaspace.dataservice为true时，不可配置"项目权限"，即使配置也不生效
metaspace.userGroup.auth.menus = 1,2,3,4,5

#增加上传hdfs的基准路径
metaspace.upload.hdfs.path=/tmp/metaspace
# 内嵌的数据源类型，多个配置项用,隔开
metaspace.datasource.type.builtIn = HIVE
# 任务调度调关系型数据血缘
metaspace.matedate.table.lineage = http://10.202.63.157:9003/taskflow/api/v2/workDashboard/upStreamTask