#hive
metaspace.hive.url=${ZETA_HIVE_SERVER2_URL}
metaspace.hive.conf=/etc/hive/conf
metaspace.hdfs.conf=/etc/hadoop/conf

#hbase
metaspace.hbase.conf=/etc/hbase/conf
metaspace.impala.url=jdbc:impala://${ZETA_IMPALA_SERVER_HOST}:${ZETA_IMPALA_SERVER_PORT}
metaspace.impala.kerberos.jdbc=${METASPACE_IMPALA_KERBEROS_JDBC}

#kerberos
metaspace.hive.principal=${ZETA_HIVE_PRINCIPAL}
metaspace.impala.principal=${METASPACE_IMPALA_PRINCIPAL}
atlas.authentication.method.kerberos=true
atlas.authentication.principal=${METASPACE_KERBEROS_PRINCIPLE}
atlas.authentication.keytab=${METASPACE_KEYTAB_NAME}
atlas.cluster.name=ms

#kakfa
atlas.kafka.hook.group.id=metaspace
atlas.kafka.mechanism=GSSAPI
atlas.kafka.sasl.kerberos.service.name=kafka
atlas.kafka.security.protocol=SASL_PLAINTEXT
atlas.kafka.zookeeper.connect=${ZETA_ZOOKEEPER_QUORUM}
atlas.kafka.bootstrap.servers=${ZETA_KAFKA_BROKERS}
atlas.kafka.zookeeper.session.timeout.ms=600000
atlas.kafka.zookeeper.connection.timeout.ms=30000
atlas.kafka.zookeeper.sync.time.ms=20
atlas.kafka.enable.auto.commit=false
atlas.kafka.session.timeout.ms=300000
atlas.kafka.max.poll.interval.ms=60000
atlas.kafka.max.poll.records=500

#kafka kerberos
atlas.jaas.KafkaClient.loginModuleName = com.sun.security.auth.module.Krb5LoginModule
atlas.jaas.KafkaClient.loginModuleControlFlag = required
atlas.jaas.KafkaClient.option.useKeyTab = true
atlas.jaas.KafkaClient.option.storeKey = true
atlas.jaas.KafkaClient.option.serviceName = kafka
atlas.jaas.KafkaClient.option.keyTab=${METASPACE_KEYTAB_NAME}
atlas.jaas.KafkaClient.option.principal=${METASPACE_KERBEROS_PRINCIPLE}

#lineage
atlas.lineage.schema.query.hive_table=hive_table where __guid='%s'\, columns
atlas.lineage.schema.query.Table=Table where __guid='%s'\, columns

#solr
atlas.graph.index.search.solr.kerberos-enabled=false
atlas.graph.index.search.backend=solr
atlas.graph.index.search.solr.mode=cloud
atlas.graph.index.search.solr.zookeeper-url=${METASPACE_SOLR_ZOOKEEPER_URL}
atlas.graph.index.search.solr.zookeeper-connect-timeout=60000
atlas.graph.index.search.solr.zookeeper-session-timeout=60000
atlas.graph.index.search.solr.wait-searcher=true

#graph
atlas.graph.storage.backend=hbase
atlas.graph.storage.hbase.table=metaspace_titan
atlas.graph.storage.hostname=${ZETA_ZOOKEEPER_QUORUM}

#notification
atlas.notification.embedded=false
atlas.notification.create.topics=true
atlas.notification.replicas=1
atlas.notification.topics=METASPACE_HOOK,METASPACE_ENTITIES

#sso
sso.login.url=${ZETA_SSO_URL}/login
sso.info.url=${ZETA_SSO_URL}/api/v2/info
sso.organization.url=${ZETA_SSO_URL}/portal/api/v5/organization
sso.organization.count.url=${ZETA_SSO_URL}/portal/api/v5/organizationsCount
sso.user.info.url=${ZETA_SSO_URL}/portal/api/v5/getAccountByID
# sso的组织结构pid,刚开始不知道，可以默认为0
sso.organization.first.pid=${SSO_ORGANIZATION_FIRST_PID}

#sso的接口前缀以及公钥、私钥配置
sso.prefix.all.url=${ZETA_SSO_URL}/api/v5/accounts
sso.prefix.like.url=${ZETA_SSO_URL}/api/v6/queryVagueUserInfo
sso.encryption = false
sso.encryption.public.key=757092eb92ba1e3c4c558a8219929a4f6d3fb0bed8bfd0e9af6df204d9d99b60
sso.encryption.private.key=b141c7e97dd3305d55935fdfff49208fc703f51d44f11e1b4449ffe2e9008412
#server
atlas.server.http.port=21001
atlas.server.https.port=21443
atlas.server.bind.address=0.0.0.0
#如果开启ha，则需要填写所有主机访问地址，用逗号隔开
atlas.rest.address=${METASPACE_API_URL}

#是否启用HA
atlas.server.ha.enabled=false
atlas.server.ids=id1,id2
atlas.server.address.id1=${METASPACE_HOST1}:21001
atlas.server.address.id2={metaspace_host2}:21001
atlas.server.ha.zookeeper.connect=${ZETA_ZOOKEEPER_QUORUM}
atlas.server.ha.zookeeper.session.timeout.ms=4000
metaspace.ha.rest.address=
#audit
atlas.audit.hbase.zookeeper.quorum=${ZETA_ZOOKEEPER_QUORUM}
atlas.audit.hbase.tablename=METASPACE_ENTITY_AUDIT_EVENTS
atlas.audit.zookeeper.session.timeout.ms=60000
atlas.authorizer.impl=simple
metaspace.mobius.url=${METASPACE_MOBIUS_URL}
#数据质量规则执行引擎 hive or impala
metaspace.quality.engine=hive
#cache
metaspace.cache.type=redis
metaspace.cache.redis.host=${ZETA_REDIS_HOST}
metaspace.cache.redis.port=${ZETA_REDIS_PORT}
metaspace.cache.redis.expiration=1800
metaspace.cache.redis.client.max=128
metaspace.cache.redis.password=${ZETA_REDIS_PASSWORD}
#secureplus
metaspace.secureplus.enable=true
metaspace.secureplus.privilegeREST=${ZETA_SP_URL}/service/privilege/hivetable

#是否启用quartz，true:开启 ，false:关闭, 多节点部署时，只允许主节点设置为true
metaspace.quartz.task.enable=${METASPACE_QUARTZ_TASK_ENABLE}
#hystrix
hystrix.command.default.execution.timeout.enabled=true
hystrix.command.default.execution.isolation.thread.timeoutInMilliseconds=600000
hystrix.command.default.circuitBreaker.sleepWindowInMilliseconds=5000
hystrix.threadpool.default.coreSize=80
hystrix.threadpool.default.maximumSize=50
hystrix.threadpool.default.maxQueueSize=100
#数据库配置
#metaspace.database.driverClassName=org.postgresql.Driver
metaspace.database.url=jdbc:postgresql://${ZETA_POSTGRESQL_HOST}:${ZETA_POSTGRESQL_PORT}/${METASPACE_DATABASE_NAME}?useUnicode=true&characterEncoding=UTF8
metaspace.database.username=${METASPACE_POSTGRE_USERNAME}
metaspace.database.password=${METASPACE_POSTGRE_PASSWORD}
metaspace.database.acquireIncrement=5
metaspace.database.initialPoolSize=50
metaspace.database.minPoolSize=50
metaspace.database.maxPoolSize=20
metaspace.database.maxIdleTime=60
metaspace.database.checkoutTimeout=20000
metaspace.database.acquireRetryAttempts=2
#邮箱配置
metaspace.mail.enable=false
metaspace.mail.user=
metaspace.mail.password=
metaspace.mail.service.mail.transport.protocol=smtp
metaspace.mail.service.mail.host=smtp.gridsum.com
metaspace.mail.service.mail.smtp.port=25

#hive和impala资源池配置
metaspace.impala.resource.pool=metaspace
metaspace.hive.queue=metaspace
metaspace.request.address=${METASPACE_API_URL}
#过滤datasocket的临时表，默认为 null
atlas.hook.hive.hive_table.ignore.pattern=.*\\.datasocket_.*_\\w{4}_\\w*_\\d{13}@.*

#安全中心地址
security.center.host=${ZETA_SP_URL}
metaspace.standalone=false
okhttp.retries=3

# kafka开关 false:开启  true:关闭。多节点部署时，只允许主节点设置为false
atlas.notification.consumer.disabled=${METASPACE_ATLAS_NOTIFICATION_CONSUMER_DISABLED}

metaspace.dataservice=true
#元数据采集路径，根目录下的adapter目录(例如：/apps/metaspace/adapter)
metaspace.adapter.dir=/apps/metaspace/adapter
metaspace.api.ploy.effective.time=30

# 配置日志审计、操作模块的目录 true标识屏蔽掉指标设计、修饰词、时间限定、审批人管理、指标域授权
metaspace.operationlog.module.moon = true
# 创建数据源配置数据源类型，多个配置项用,隔开（目前支持HIVE,IMPALA,MYSQL,POSTGRESQL,ORACLE,DB2,SQLSERVER,OSCAR）
metaspace.datasource.type = ${METASPACE_DATASOURCE_TYPE}
# API项目管理-创建API配置数据源类型，多个配置项用,隔开（目前支持HIVE,IMPALA,MYSQL,POSTGRESQL,ORACLE,DB2,SQLSERVER,OSCAR）
metaspace.datasource.api.type = ${METASPACE_DATASOURCE_API_TYPE}
#用户组管理-配置权限下页签列表，配置具体的编号（1:成员,2:技术目录权限,3:业务目录权限,4:数据源权限,5:项目权限,6:指标域权限），metaspace.dataservice为true时，不可配置"项目权限"，即使配置也不生效
metaspace.userGroup.auth.menus = 1,2,3,4,5,6,7,8,9

# livy 地址
livy.uri=${METASPACE_LIVY_URL}/batches
# livy 是否开启 kerberos
livy.need.kerberos=true
livy.server.auth.kerberos.principal=${METASPACE_KERBEROS_PRINCIPLE}
livy.server.auth.kerberos.keytab=${METASPACE_KEYTAB_NAME}
# livy 提交后获取 appId 重试次数
livy.task.appId.retry.count=3
livy.retry.sleep.time=20000

#任务调度指标链路接口
etl.indexlink.address=${METASPACE_ETL_INDEXLINK_ADDRESS}
#是否开启获取任务调度节点信息
etl.indexLink.enable=true

# 内嵌的数据源类型，多个配置项用,隔开
metaspace.datasource.type.builtIn = HIVE

#kafka.connect请求路径
oracle.kafka.connect.urls=${METASPACE_ORACLE_KAFKA_CONNECT_URLS}
#oracle元数据topic
#oracle.metadata.topic=ORACLE_METADATA

# 源信息登记文件上传路径 hdfs
metaspace.upload.hdfs.path=/apps/metaspace/SourceInformation

#邮件配置
notice.email.url=${METASPACE_NOTICE_EMAIL_URL}

#元数据采集任务执行完成后是否检查创建并开启kafka connector(开启kafka connector后可实时更新元数据)
auto.add.kafka.connector = false

# 重启服务-任务是否强制停止 服务器设置为true，本地调试设置为false
metaspace.sync.task.status = true

# 1.14.0版本新增

# 任务调度调关系型数据血缘
metaspace.matedate.table.lineage = ${METASPACE_MATEDATE_TABLE_LINEAGE}
# 站内信url
sendMessage.url=${METASPACE_SENDMESSAGE_URL}
#元数据采集变化发送站内信，邮件？ 1：邮件，2：站内信，都发（1,2）用,隔
sendNotice.type=${METASPACE_SENDNOTICE_TYPE}

#1.15.0版本新增
#数据管理配置云平台的域名
metaspace.mobius.domain.name = ${METASPACE_MOBIUS_DOMAIN_NAME}








